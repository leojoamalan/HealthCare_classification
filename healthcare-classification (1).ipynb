{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2764486,"sourceType":"datasetVersion","datasetId":1686903},{"sourceId":8548522,"sourceType":"datasetVersion","datasetId":5107879},{"sourceId":8590551,"sourceType":"datasetVersion","datasetId":5138371},{"sourceId":8590701,"sourceType":"datasetVersion","datasetId":5138484},{"sourceId":8590982,"sourceType":"datasetVersion","datasetId":5138705}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-05T04:07:59.838317Z","iopub.execute_input":"2024-06-05T04:07:59.838708Z","iopub.status.idle":"2024-06-05T04:08:45.279059Z","shell.execute_reply.started":"2024-06-05T04:07:59.838679Z","shell.execute_reply":"2024-06-05T04:08:45.278182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport  matplotlib.pyplot as plt\nimport cv2\nimport PIL\nfrom tqdm import tqdm\nimport shutil","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:08:45.280543Z","iopub.execute_input":"2024-06-05T04:08:45.280930Z","iopub.status.idle":"2024-06-05T04:08:45.461597Z","shell.execute_reply.started":"2024-06-05T04:08:45.280903Z","shell.execute_reply":"2024-06-05T04:08:45.460885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = \"/kaggle/input/dataset1/agument\"\ncontent = os.listdir(data_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:09:12.638769Z","iopub.execute_input":"2024-06-05T04:09:12.639499Z","iopub.status.idle":"2024-06-05T04:09:12.645869Z","shell.execute_reply.started":"2024-06-05T04:09:12.639468Z","shell.execute_reply":"2024-06-05T04:09:12.645003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:09:16.284666Z","iopub.execute_input":"2024-06-05T04:09:16.285353Z","iopub.status.idle":"2024-06-05T04:09:16.291989Z","shell.execute_reply.started":"2024-06-05T04:09:16.285323Z","shell.execute_reply":"2024-06-05T04:09:16.291072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = \"/kaggle/input/dataset1/agument\"\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:09:18.026029Z","iopub.execute_input":"2024-06-05T04:09:18.026907Z","iopub.status.idle":"2024-06-05T04:09:18.031042Z","shell.execute_reply.started":"2024-06-05T04:09:18.026872Z","shell.execute_reply":"2024-06-05T04:09:18.029947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counts = {}\n\nfor l in content:\n    counts[l] = len(os.listdir(os.path.join(img_path, l)))\n\n    \nplt.figure(figsize=(12, 6))\n\nplt.bar(range(len(counts)), list(counts.values()), align='center')\nplt.xticks(range(len(counts)), list(counts.keys()), fontsize=12, rotation=40)\nplt.xlabel('class label', fontsize=13)\nplt.ylabel('class size', fontsize=13)\nplt.title('Cyst , stone , normal, tumors', fontsize=15);","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:09:19.177787Z","iopub.execute_input":"2024-06-05T04:09:19.178629Z","iopub.status.idle":"2024-06-05T04:09:19.438759Z","shell.execute_reply.started":"2024-06-05T04:09:19.178595Z","shell.execute_reply":"2024-06-05T04:09:19.437781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''img_paths1 = [os.path.join(img_path +\"/\"+l+\"/\"+l+'- (10).jpg') for l in content]\n\nimg_paths = img_paths1 + [os.path.join(img_path+\"/\"+l+\"/\"+l+'- (100).jpg') for l in content]\n\ndef plot_sat_imgs(paths):\n    plt.figure(figsize=(15, 8))\n    for i in range(8):\n        plt.subplot(4, 5, i+1, xticks=[], yticks=[])\n        img = PIL.Image.open(paths[i], 'r')\n        plt.imshow(np.asarray(img))\n        plt.title(paths[i].split('/')[-2])\n\nplot_sat_imgs(img_paths)'''","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:09:20.565453Z","iopub.execute_input":"2024-06-05T04:09:20.566271Z","iopub.status.idle":"2024-06-05T04:09:20.572670Z","shell.execute_reply.started":"2024-06-05T04:09:20.566238Z","shell.execute_reply":"2024-06-05T04:09:20.571757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\ninput_shape = (299,299,3)\nchannels = 3","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:09:21.418788Z","iopub.execute_input":"2024-06-05T04:09:21.419158Z","iopub.status.idle":"2024-06-05T04:09:21.423417Z","shell.execute_reply.started":"2024-06-05T04:09:21.419128Z","shell.execute_reply":"2024-06-05T04:09:21.422473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#image generator in tensorflow\nimport tensorflow\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:09:22.620040Z","iopub.execute_input":"2024-06-05T04:09:22.620388Z","iopub.status.idle":"2024-06-05T04:09:34.119810Z","shell.execute_reply.started":"2024-06-05T04:09:22.620357Z","shell.execute_reply":"2024-06-05T04:09:34.118793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir('/kaggle/working/train_dir')\nos.mkdir('/kaggle/working/test_dir')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:09:34.123063Z","iopub.execute_input":"2024-06-05T04:09:34.123879Z","iopub.status.idle":"2024-06-05T04:09:34.127949Z","shell.execute_reply.started":"2024-06-05T04:09:34.123850Z","shell.execute_reply":"2024-06-05T04:09:34.127046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir('/kaggle/working/Augument_dir')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:09:34.170640Z","iopub.execute_input":"2024-06-05T04:09:34.171200Z","iopub.status.idle":"2024-06-05T04:09:34.175986Z","shell.execute_reply.started":"2024-06-05T04:09:34.171172Z","shell.execute_reply":"2024-06-05T04:09:34.174692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\n\n# Specify the input and output directories\ninput_dir = \"/kaggle/input/dataset1/agument\"\noutput_dir = \"/kaggle/working/Augument_dir\"\n\n# Loop through all files in the input directory\nfor filename in os.listdir(input_dir):\n        for i in os.listdir(input_dir+\"/\"+filename):\n            if not os.path.exists(os.path.join(output_dir,filename)):\n                os.mkdir(os.path.join(output_dir,filename))\n                image = Image.open(os.path.join(input_dir,filename, i))\n                # Convert the image to PNG format\n                output_filename = i+ \".jpeg\"\n                image.save(os.path.join(output_dir,filename, output_filename), \"JPEG\")\n            else:\n                image = Image.open(os.path.join(input_dir,filename, i))\n                output_filename = i + \".jpeg\"\n                image.save(os.path.join(output_dir,filename, output_filename), \"JPEG\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:09:37.929022Z","iopub.execute_input":"2024-06-05T04:09:37.929988Z","iopub.status.idle":"2024-06-05T04:13:08.235867Z","shell.execute_reply.started":"2024-06-05T04:09:37.929945Z","shell.execute_reply":"2024-06-05T04:13:08.235052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content = os.listdir(input_dir)\nfor i in content:\n    print(len(os.listdir(os.path.join(output_dir,i))))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:13:08.237657Z","iopub.execute_input":"2024-06-05T04:13:08.238006Z","iopub.status.idle":"2024-06-05T04:13:08.255834Z","shell.execute_reply.started":"2024-06-05T04:13:08.237973Z","shell.execute_reply":"2024-06-05T04:13:08.254998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nTRAIN_DIR = '/kaggle/working/train_dir'\nTEST_DIR = '/kaggle/working/test_dir'\nBATCH_SIZE = batch_size\nNUM_CLASSES=len(content)\nINPUT_SHAPE = (299, 299, 3)\nCLASS_MODE = 'categorical'\nfor path in (TRAIN_DIR, TEST_DIR):\n    if not os.path.exists(path):\n        os.mkdir(path)\nfor l in content:\n    \n    if not os.path.exists(os.path.join(TRAIN_DIR, l)):\n        os.mkdir(os.path.join(TRAIN_DIR, l))\n\n    if not os.path.exists(os.path.join(TEST_DIR, l)):\n        os.mkdir(os.path.join(TEST_DIR, l))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:13:08.256766Z","iopub.execute_input":"2024-06-05T04:13:08.257034Z","iopub.status.idle":"2024-06-05T04:13:08.849943Z","shell.execute_reply.started":"2024-06-05T04:13:08.257002Z","shell.execute_reply":"2024-06-05T04:13:08.849062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = \"/kaggle/working/Augument_dir\"\ndata ={}\nfor l in content:\n    for img in os.listdir(img_path+'/'+l):\n        data.update({os.path.join(img_path+'/'+l+'/'+ img): l})","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:13:08.852006Z","iopub.execute_input":"2024-06-05T04:13:08.852299Z","iopub.status.idle":"2024-06-05T04:13:08.909799Z","shell.execute_reply.started":"2024-06-05T04:13:08.852274Z","shell.execute_reply":"2024-06-05T04:13:08.908439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating an image data frame\nx = pd.Series(list(data.keys()))\ny = pd.get_dummies(pd.Series(data.values()))\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=69)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:13:08.911172Z","iopub.execute_input":"2024-06-05T04:13:08.911575Z","iopub.status.idle":"2024-06-05T04:13:08.935346Z","shell.execute_reply.started":"2024-06-05T04:13:08.911540Z","shell.execute_reply":"2024-06-05T04:13:08.934336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = PIL.Image.open(x[0], 'r')\nplt.imshow(np.asarray(img))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:13:08.937071Z","iopub.execute_input":"2024-06-05T04:13:08.937922Z","iopub.status.idle":"2024-06-05T04:13:09.314238Z","shell.execute_reply.started":"2024-06-05T04:13:08.937881Z","shell.execute_reply":"2024-06-05T04:13:09.313305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for train_idx, test_idx in split.split(x, y):\n    \n    train_paths = x[train_idx]\n    test_paths = x[test_idx]\n    new_train_paths = [re.sub('/kaggle/working/Augument_dir', '/kaggle/working/train_dir', i) for i in train_paths]\n    new_test_paths = [re.sub('/kaggle/working/Augument_dir', '/kaggle/working/test_dir', i) for i in test_paths]\n\n    train_path_map = list((zip(train_paths, new_train_paths)))\n    test_path_map = list((zip(test_paths, new_test_paths)))\n    \n    print(\"moving training files..\")\n    for i in tqdm(train_path_map):\n        if not os.path.exists(i[1]):\n            if not os.path.exists(re.sub('training', 'testing', i[1])):\n                shutil.copy(i[0], i[1])\n    \n    print(\"moving testing files..\")\n    for i in tqdm(test_path_map):\n        if not os.path.exists(i[1]):\n            if not os.path.exists(re.sub('training', 'testing', i[1])):\n                shutil.copy(i[0], i[1])","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:13:09.315404Z","iopub.execute_input":"2024-06-05T04:13:09.315707Z","iopub.status.idle":"2024-06-05T04:13:12.181252Z","shell.execute_reply.started":"2024-06-05T04:13:09.315682Z","shell.execute_reply":"2024-06-05T04:13:12.180364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:13:12.182275Z","iopub.execute_input":"2024-06-05T04:13:12.182576Z","iopub.status.idle":"2024-06-05T04:13:12.187369Z","shell.execute_reply.started":"2024-06-05T04:13:12.182550Z","shell.execute_reply":"2024-06-05T04:13:12.186452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir ='/kaggle/working/train_dir'\ntest_dir ='/kaggle/working/test_dir'","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:13:12.188419Z","iopub.execute_input":"2024-06-05T04:13:12.188688Z","iopub.status.idle":"2024-06-05T04:13:12.202269Z","shell.execute_reply.started":"2024-06-05T04:13:12.188666Z","shell.execute_reply":"2024-06-05T04:13:12.201372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,# Rescaling the images\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    zca_epsilon=1e-06,\n    brightness_range=None,\n    cval=0.0,\n    vertical_flip=True,\n    preprocessing_function=None,\n    data_format=None,\n    validation_split=0.0,\n    interpolation_order=1,\n    dtype=None\n)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(299, 299),  # Resize all images to 150x150\n    batch_size=batch_size,\n    class_mode='categorical'\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(299, 299),\n    batch_size=batch_size,\n    class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:13:12.205888Z","iopub.execute_input":"2024-06-05T04:13:12.206161Z","iopub.status.idle":"2024-06-05T04:13:12.858036Z","shell.execute_reply.started":"2024-06-05T04:13:12.206136Z","shell.execute_reply":"2024-06-05T04:13:12.857286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_generator.class_indices)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:13:12.859120Z","iopub.execute_input":"2024-06-05T04:13:12.859473Z","iopub.status.idle":"2024-06-05T04:13:12.864069Z","shell.execute_reply.started":"2024-06-05T04:13:12.859410Z","shell.execute_reply":"2024-06-05T04:13:12.863200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_STEPS = train_generator.samples//BATCH_SIZE\nN_VAL_STEPS = test_generator.samples//BATCH_SIZE\nN_EPOCHS = 100","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:13:12.865080Z","iopub.execute_input":"2024-06-05T04:13:12.865367Z","iopub.status.idle":"2024-06-05T04:13:12.873716Z","shell.execute_reply.started":"2024-06-05T04:13:12.865344Z","shell.execute_reply":"2024-06-05T04:13:12.872873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model building\nimport tensorflow as tf\nfrom keras.models import Model\nfrom keras.layers import Dense , Flatten,Dropout,MaxPooling2D\nfrom keras.optimizers import Adam , Adagrad,Adadelta","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:13:12.874708Z","iopub.execute_input":"2024-06-05T04:13:12.874966Z","iopub.status.idle":"2024-06-05T04:13:12.882802Z","shell.execute_reply.started":"2024-06-05T04:13:12.874944Z","shell.execute_reply":"2024-06-05T04:13:12.881969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications import VGG16,VGG19\nfrom sklearn.metrics import precision_recall_fscore_support, confusion_matrix, fbeta_score, accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-06-05T04:13:12.883709Z","iopub.execute_input":"2024-06-05T04:13:12.883961Z","iopub.status.idle":"2024-06-05T04:13:12.892262Z","shell.execute_reply.started":"2024-06-05T04:13:12.883930Z","shell.execute_reply":"2024-06-05T04:13:12.891454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_base = VGG16(include_top=False,\n                              weights='/kaggle/input/model-weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', \n                              input_shape=input_shape)\nmodel = conv_base.output\n\nmodel = Flatten()(model)\nmodel = Dense(2048, activation='relu')(model)\nmodel = Dropout(0.2)(model)\nmodel = Dense(2048, activation='relu')(model)\nmodel = Dropout(0.2)(model)\noutput_layer = Dense(len(content), activation='softmax')(model)\nmodel = Model(inputs=conv_base.input, outputs=output_layer)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-06-04T07:06:39.743362Z","iopub.execute_input":"2024-06-04T07:06:39.744217Z","iopub.status.idle":"2024-06-04T07:06:40.736013Z","shell.execute_reply.started":"2024-06-04T07:06:39.744184Z","shell.execute_reply":"2024-06-04T07:06:40.734914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\ndef custom_vgg16(input_shape, num_classes):\n    model = Sequential()\n\n    # Convolutional layers\n    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    # Fully connected layers\n    model.add(Flatten())\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n\n    return model\n\n# Example usage:\ninput_shape = (299, 299, 3)  # Example input shape for image data\nnum_classes = 4  # Number of output classes\nmodel = custom_vgg16(input_shape, num_classes)\n\n# Print model summary\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T04:35:59.210499Z","iopub.execute_input":"2024-06-04T04:35:59.211120Z","iopub.status.idle":"2024-06-04T04:35:59.555739Z","shell.execute_reply.started":"2024-06-04T04:35:59.211089Z","shell.execute_reply":"2024-06-04T04:35:59.554897Z"}}},{"cell_type":"code","source":"initial_learning_rate = 0.01\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=100000,\n    decay_rate=0.96,\n    staircase=True\n)\noptimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T07:06:42.349999Z","iopub.execute_input":"2024-06-04T07:06:42.350417Z","iopub.status.idle":"2024-06-04T07:06:42.359357Z","shell.execute_reply.started":"2024-06-04T07:06:42.350386Z","shell.execute_reply":"2024-06-04T07:06:42.358116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" model.compile(optimizer='Adam', loss='categorical_crossentropy',\n                 metrics=['categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-06-04T07:06:43.228056Z","iopub.execute_input":"2024-06-04T07:06:43.228830Z","iopub.status.idle":"2024-06-04T07:06:43.238660Z","shell.execute_reply.started":"2024-06-04T07:06:43.228794Z","shell.execute_reply":"2024-06-04T07:06:43.237656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-04T07:06:44.097943Z","iopub.execute_input":"2024-06-04T07:06:44.098712Z","iopub.status.idle":"2024-06-04T07:06:44.143731Z","shell.execute_reply.started":"2024-06-04T07:06:44.098683Z","shell.execute_reply":"2024-06-04T07:06:44.142361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=100,  # Number of batches per epoch\n    epochs=50,\n    validation_data=test_generator,\n    validation_steps=50  # Number of batches for validation\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T07:06:44.818556Z","iopub.execute_input":"2024-06-04T07:06:44.819376Z","iopub.status.idle":"2024-06-04T07:20:07.684545Z","shell.execute_reply.started":"2024-06-04T07:06:44.819343Z","shell.execute_reply":"2024-06-04T07:20:07.683340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"initial_learning_rate = 0.01\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=100000,\n    decay_rate=0.96,\n    staircase=True\n)\noptimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n# model.compile(optimizer=optimizer, loss='mean_squared_error')\n\n# # Train the model\n# history = model.fit(train_data, train_labels, epochs=50, validation_data=(val_data, val_labels))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:57:17.246954Z","iopub.execute_input":"2024-06-05T05:57:17.247643Z","iopub.status.idle":"2024-06-05T05:57:17.254768Z","shell.execute_reply.started":"2024-06-05T05:57:17.247610Z","shell.execute_reply":"2024-06-05T05:57:17.253734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = tf.keras.applications.InceptionV3(\n    include_top=True,\n    weights='/kaggle/input/inceptions/inception_v3_weights_tf_dim_ordering_tf_kernels.h5',\n    input_tensor=None,\n    input_shape=None,\n    pooling=None,\n    classes=1000,\n    classifier_activation='softmax'\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:57:18.146184Z","iopub.execute_input":"2024-06-05T05:57:18.146537Z","iopub.status.idle":"2024-06-05T05:57:21.384461Z","shell.execute_reply.started":"2024-06-05T05:57:18.146509Z","shell.execute_reply":"2024-06-05T05:57:21.383542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\n\nbase_model = InceptionV3(weights='/kaggle/input/inceptions/inception_v3_weights_tf_dim_ordering_tf_kernels.h5', include_top=True)\nx = base_model.output\nx = Dense(1024, activation='relu')(x)\npredictions = Dense(4, activation='softmax')(x)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:57:21.386383Z","iopub.execute_input":"2024-06-05T05:57:21.386721Z","iopub.status.idle":"2024-06-05T05:57:23.899060Z","shell.execute_reply.started":"2024-06-05T05:57:21.386694Z","shell.execute_reply":"2024-06-05T05:57:23.898231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = Model(inputs=base_model.input, outputs=predictions)\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\n\nmodel1.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-06-05T07:35:21.079627Z","iopub.execute_input":"2024-06-05T07:35:21.079956Z","iopub.status.idle":"2024-06-05T07:35:21.140474Z","shell.execute_reply.started":"2024-06-05T07:35:21.079921Z","shell.execute_reply":"2024-06-05T07:35:21.139502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model1.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T06:32:03.862179Z","iopub.execute_input":"2024-06-05T06:32:03.862476Z","iopub.status.idle":"2024-06-05T06:32:03.866523Z","shell.execute_reply.started":"2024-06-05T06:32:03.862452Z","shell.execute_reply":"2024-06-05T06:32:03.865484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.fit(\n    train_generator,\n    steps_per_epoch=100,  # Number of batches per epoch\n    epochs=30,\n    validation_data=test_generator,\n    validation_steps=50\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T07:35:21.142246Z","iopub.execute_input":"2024-06-05T07:35:21.142656Z","iopub.status.idle":"2024-06-05T08:14:11.788130Z","shell.execute_reply.started":"2024-06-05T07:35:21.142622Z","shell.execute_reply":"2024-06-05T08:14:11.787153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.save('inceptionv3.h5')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:37:48.367160Z","iopub.execute_input":"2024-06-05T08:37:48.367551Z","iopub.status.idle":"2024-06-05T08:37:48.964184Z","shell.execute_reply.started":"2024-06-05T08:37:48.367520Z","shell.execute_reply":"2024-06-05T08:37:48.963030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load and preprocess an example image\nimg_path = '/kaggle/working/train_dir/Cyst/Cyst- (687)_0_1764.jpeg.jpeg'  # Change this to the path of your image\nimg = load_img(img_path, target_size=(299, 299))\nimg_array = img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)\nimg_array = preprocess_input(img_array)\n\n# Predict the class of the image\npreds = model.predict(img_array)\nprint('Predicted:', decode_predictions(preds, top=3)[0])\n\n# Fine-tuning (optional)\n# Unfreeze some layers of the base model for fine-tuning\nfor layer in base_model.layers[-20:]:\n    layer.trainable = True\n\n# Recompile the model after unfreezing\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Now you can train your model on your dataset\n# model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T08:06:22.416616Z","iopub.execute_input":"2024-06-04T08:06:22.417038Z","iopub.status.idle":"2024-06-04T08:06:22.629800Z","shell.execute_reply.started":"2024-06-04T08:06:22.417004Z","shell.execute_reply":"2024-06-04T08:06:22.628195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}